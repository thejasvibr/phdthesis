--- 
title: "Theoretical and empirical investigation of echolocation in bat groups"
author: "Thejasvi Beleyur"
date: "$`r Sys.Date()`$"
site: bookdown::bookdown_site
documentclass: book
bibliography: ["beleyur-goerlitz-2020-refs.bib", "tacost-references.bib","cotdoa-filtered.bib","intro-discussion-refs.bib","itsfm-references.bib"]
biblio-style: apalike
link-citations: true
description: "A thesis" 
output:
  bookdown::pdf_book:
    latex_engine: lualatex
    includes:
      in_header: preamble.tex
always_allow_html: true
---
```{r, include=FALSE, echo=FALSE}
options(tinytex.verbose = TRUE)
# does this actually work: https://stackoverflow.com/a/53287111 - the cleardoublepage part is from here!!!
```

# Summary {#summary}
Animals in groups gain a variety of advantages while also managing part of the challenges. From a sensory perspective being part of a group challenges the individual sensory system in the multitude of signals to be dealt with. Much work has gone into understanding how passive sensing animals (that rely on vision and hearing), that act as 'receivers' of signals, manage to emit and receive signals in groups. Multiple passive sensing animals may perceive their environment and signals in it without affecting the perception of their neighbour. Active sensing animals in contrast emit probes of energy to detect their surroundings. When multiple active sensing animals form groups, it is expected that they will mutually interfere, or jam each other's sensory systems. Despite the possibility of jamming in groups, many active sensing animals exhibit social behaviours. In this thesis I investigate how active sensing echolocating bats manage to echolocate in groups using a combination of computational simulations, field studies and also contribute methods that ease acoustic tracking and the analysis of echolocation calls.  

In Chapter \@ref(cpnchapter) I quantify the sensory challenge of group echolocation. In groups, the returning echoes of each bat will be overlapped by the intense calls and echoes of their neighbours. The problem of jamming is expected to increase non-linearly with group size. Despite this expectation, bats form large groups in nature. I estimate the detriment in echo detection that bats may experience with increasing group size using computational simulations. I build an experimentally parametrised model implementing details of bat audition, sound propagation and group geometry. I find that bats may still be detecting echoes in group sizes of up to a hundred. Bats in such large groups however may be detecting one neighbour only around one in three calls. The model assumed a simplified auditory system, and thus represents a lower-bound for echo detection. My model represents the first attempt at a biologically parametrised model of group echolocation. The results raise the question about the severity of group echolocation and estimates the sensory input available for collective motion in bat aggregations. 

Chapter \@ref(hbcchapter) is an observational study in the field looking into the echolocation of high duty-cycle bats across group size. High duty-cycle bats emit long calls with short pauses in between. Their long calls and frequent call emission increases the likelihood of call-echo overlaps even in small groups. Due to the challenge of analysing overlapping calls, not much work has been done studying high duty-cycle bat group echolocation, and have primarily been done in flightroom conditions. Using audio and video recordings of free-flying bats in a cave, I analyse the difference in echolocation when CF-FM bats fly alone and when in groups of upto four bats. I develop a package to automate the segmentation and measurent of individual calls into their component parts (described in Chapter \@ref(itsfmchapter)). I also develop a method to analyse audio with overlapping calls and use it in conjunction with simulations to understand if bats alter their echolocation in groups. The results suggest no major changes between the measured call parameters between bats flying alone and in groups. The study contributes know-how in the analysis of overlapping calls and automation of individual call analysis. The study highlights the robustness of bat echolocation, and highlights the importance of field studies to characterise the capabilities of active sensing animals. 

From high duty-cycle bats, Chapter \@ref(ushichkachapter) reports the details of long-term dataset collected at the Orlova Chuka cave looking at group echolocation in free-flying low duty-cycle bats. Low duty-cycle bats emit short calls with longer silences in between. Despite the occasional calling behaviour of FM bats, results from modelling in Chapter \@ref(cpnchapter) show that echo detection can already be affected from group sizes of 30 bats onwards. I present the methods and investigative potential behind what I call the *Ushichka* dataset. *Ushichka* is a multi-channel, multi-sensor dataset of *Myotis myotis* and *Myotis blythii* bats echolocating over a range of group sizes between 1-30 in a cave chamber. The dataset consists of synchronised microphone and thermal-camera arrays, along with a LiDAR scan of the cave chamber. The microphone arrays capture the call emissions, while camera arrays capture flight trajectories. The LiDAR scan provides a contextual 3D record of the volume bats behave in. Given the position, call emission and LiDAR data from the dataset, we can for the first time reconstruct the sensory inputs of individual bats in groups by simulating sound propagation.  Analysing multi-bat audio brings its own challenges such as call overlaps and multi-channel correspondence. However, it is my opinion that the group sizes observed group sizes of upto ~30 bats corresponds to a 'Goldilocks' zone, where current analysis methods may be able to perform satisfactory acoustic tracking. Unlike comparable studies, *Ushichka* ,is to my knowledge, the first such dataset to record the collective behaviour of bats in the wild with multiple sensors simultaneously.

Chapter \@ref(sfscotdoa) marks the beginning of a series of methodological reports contributing to the study of group echolocation. Multi-microphone arrays are central to studies of echolocation. Acoustic arrays provide access to the 3D position of the calling bat, but also add to the logistical effort during field work. Most arrays consist of microphones placed on bulky frames, that are difficult to carry. Their typically rectilinear forms stand out in natural settings and result in artifactual inspection behaviours by the animals themselves. In place of frames, placing microphones freely in the field also brings the heavy burden of having to measure microphone positions each time. In Chapter \@ref(sfscotdoa) I present the results of a collaboration towards a frame-less, measurement-free approach to acoustic tracking. The workflow involves freely placing microphones in a volume and recording a series of common sounds on all channels. The time-differences-of-arrival between channels are then used to estimate microphone positions automatically. In this report we show the sucessful estimation of freely-placed mics in a cave setting to within $\pm$ 4cm of ground-truthed measurements. This is the first time such a  methodology has been applied in the field of echolocation, and it promises to expand the freedom and scale of multi-microphone arrays under field and laboratory settings. Once the bioacoustician is freed from the shackles of microphone frames, naturally available structures can be used to create large-scale inconspicuous arrays, that are also logistically tractable. 

The accuracy of acoustic tracking is affected by a host of factors including array geometry, source sound type and location of sound emission. When designing a microphone array from scratch, or when characterising an array post-hoc, it is important to understand the baseline accuracy the system will show. Chapter \@(tacostchapter) presents the ```tacost``` software package that generates simulated multi-channel audio according to the user-specified parameters. While ```tacost``` does not perform acoustic tracking itself, it generates the simulated data to allow the comparison of different array geometries, or source sounds for instance. ```tacost``` is a tool to assist the optimisation of acoustic tracking systems during the conception phase, and after recordings have been performed. 



English  English English English English English English English English English English  English English English English English English English English English English  English English English English English English English English English English  English English English English English English English English English English  English English English English English English English English English English  English English English English English English English English English English  English English English English English English English English English English  English English English English English English English English English English  English English English English English English English English English 


\newpage

# Zusammenfassung {#zusammenf}

Deutsch Deutsch Deutsch Deutsch Deutsch Deutsch Deutsch DeutschDeutsch Deutsch Deutsch Deutsch Deutsch Deutsch Deutsch Deutsch DeutschDeutschDeutsch Deutsch Deutsch Deutsch Deutsch Deutsch Deutsch DeutschDeutschDeutsch Deutsch Deutsch Deutsch Deutsch Deutsch Deutsch DeutschDeutschDeutsch Deutsch Deutsch Deutsch Deutsch Deutsch Deutsch DeutschDeutschDeutsch Deutsch Deutsch Deutsch Deutsch Deutsch Deutsch DeutschDeutschDeutsch Deutsch Deutsch Deutsch Deutsch Deutsch Deutsch DeutschDeutschDeutsch Deutsch Deutsch Deutsch Deutsch Deutsch Deutsch DeutschDeutschDeutsch Deutsch Deutsch Deutsch Deutsch Deutsch Deutsch DeutschDeutschDeutsch Deutsch Deutsch Deutsch Deutsch Deutsch Deutsch DeutschDeutschDeutsch Deutsch Deutsch Deutsch Deutsch Deutsch Deutsch DeutschDeutschDeutsch Deutsch Deutsch Deutsch Deutsch Deutsch Deutsch DeutschDeutschDeutsch Deutsch Deutsch Deutsch Deutsch Deutsch Deutsch DeutschDeutschDeutsch Deutsch Deutsch Deutsch Deutsch Deutsch Deutsch DeutschDeutschDeutsch Deutsch Deutsch Deutsch Deutsch Deutsch Deutsch DeutschDeutschDeutsch Deutsch Deutsch Deutsch Deutsch Deutsch Deutsch DeutschDeutsch

\newpage 
 
 \
 \
 \
 \
 \

*Bulla! I know not who I am,*

*Bulla! I know not who I am*

...

*Nor am I the believer in the mosque,*

*Nor am I in the rituals of the infidel,*

*Nor am I the pure in the impure,*

*Nor am I inherent in the Vedas*

...

*Nor am I of the water nor of the land,*

*Nor am I fire nor air,*

*Bulla! I know not who I am,*

*Nor am I Arabic nor from Lahore,*

...

*Nor did I name myself,*

*Beginning or end I know just the self,*

*Do not acknowledge duality,*

*There's none wiser than I*\



*Who is this Bulla Shah?*\

*Bulla! I know not who I am,*

*Bulla! I know not who I am*

 - Bulla Shah, Sufi mystic and poet ^[I interpret this poem as an apt expression of the simultaneous pleasure, confusion and contentment gained from inter-disciplinary research]. Translation by @bullashahtransl.

*Echolocation is still a topic that resists neat classification into any conventional category of science. It ramifies into widely different scientific disciplines including ethology, mammalogy, physiology, psychology, acoustics, and the mathematical theory of signal detectionl. The results of new investigations have reemphasized the necessity of a broad biological perspective for any serious appreciation of echolocation.*

 - Donald Griffin, Listening in the Dark

\newpage

# General Introduction 

Animal sensory systems and behaviours evolve in response to a host of selection pressures such as predators, food and the environment [@EndlerREF]. Moths with ultrasonic hearing are able to evade echolocating bats, that have in turn developed echolocation strategies that evade moth hearing [@REFS]. The physical environment (eg. light, heat, humidity) also plays a strong role in selecting sensory systems. Cave fish inhabiting dark cave systems repeatedly evolve a loss of vision [@jeffery2001cavefish], while ABCDEFGHIJKLMON. The social environment, consisting of other conspecifics and interactions with them, is also of great importance in the life-cycle of most sexually reproducing animals. Even classically solitary animals such as tigers and spiders will (or seek to) encounter mates over the course of their life time. Sexual selection moulds behaviours and sensory systems as seen in territorial displays and female sensory drives in a wide variety of taxa [@REF] as epitomised by the dance and colourful patterns of the male peacock spider [@REF]. 

The social environment of animals in long-term social groups (eusocial insects and mammals) or short-term groups (eg. lekks, maternal colonies) is particularly filled with a continuous stream of multi-modal stimuli and presents a host of challenges that individual sensory systems and behaviours have evolved with. To illustrate this point, we only need to look at ourselves as a species. The sensory challenge of conducting a conversation with a person in the middle of a gathering lies in trying to listen to what the person opposite is saying, and in trying to make ourselves heard. This problem has been termed the 'cocktail party problem' [@cherry1953a] and our own sensory systems and behaviours show a variety of responses to such situations. As 'emitters' of speech we talk louder in the presence of background noise (the Lombard effect @). As 'receivers' there are a host of auditory and attentional processes that come into play. Our pinnae provide directional cues to allowing us to hone into sounds coming from the relevant direction [@yost2007a] while the auditory centers in the brain are able to selectively choose the best speech signals (with the higher signal-to-noise ratio) from either cochlea [@brungart2012better]. Many other taxa such as birds, frogs and crickets face very similar cocktail-party like issues [@bee2008a;@brumm2005a], and show a diversity of strategies to solve the challenges of dealing with emitting and detecting signals that overlap in time and are very similar spectrally. As emitters, animals may attempt to avoid signal overlap wherever possible, for instance in certain species of frogs and crickets, pairs of males may alternate their calls to reduce temporal overlap [@bee2008a;@hartbauer2016rhythm], while in other species males synchronise their calls to increase the conspicuosness of the emitted signal and attract females over a longer distance range [@greenfield2015signal]. As receivers, animals in groups need to be able to identify and separate signal sources and move in response to them. In certain vertebrates such as penguins, bats and seals, young are raised in large maternal colonies. Mothers leave their young ones in these colonies as they go to forage and return afterwards. A common strategy seen for mother-young reunion  is the presence of individual-specific contact calls (and the ability to detect the inter-individual variation) in either the mother or the pup [@bradbury1998principles]. The task of detecting a pup's or mother's call in the midst of a few hundreds to thousand other individuals' calls is no trivial task, and mistakes do occur: 17% of observed mother-pup pairs in a Mexican free-tailed bat (*Tadarida brasiliensis*) colony [@mccracken1984communal] were found to be unrelated genetically. 

Animal sensory systems are more than static 'receivers' or 'emitters', but exist in a dynamic interaction with the outside world through sensorimotor loops that form the basis of behaviours such as walking, running, flight [@@@@REEEEFFF]. Individuals in groups must also deal with the consequences of having conspecifics around even in simple tasks such as movement and path-planning. In contrast to moving in surroundings with stationary objects and predictable trajectories, moving among conspecifics implies anticipating and updating one's own direction of movement constantly. The apparent ease with which individuals in a murmuration of starlings or school of fish move belies the complex underlying sensorimotor loops that drive the movement of each individual in the group. These collective behaviours can be replicated in computational agent-based models with abstract and simple behavioural heuristics based on the relative proximity and position of each agent's neighbours [@reynolds1987a;@couzin2002a]. The behavioural heuristics in these models mimics what animals in a group are likely to be doing [@herbert2016understanding], and broadly consists of the following cycle: 1) the individual assessing the relative position and movement direction of its neighbours, 2) using a decision criterion to integrate information on the neighbour positions and movements and 3) moving in a direction using the integrated information. 

A key step in the initiation and maintenance of any collective behaviour is neighbour detection through the sensory modalities available to the animal. Many of the collective movements studied experimentally to date have been in visually dominant animals [@pita2016collective] such as birds, fish, mammals and flies. The fact that each animal acts as an independent receiver of light, and does not affect the amount of light received by others majorly (aside from light obstruction due to body opacity) means that visually driven collective behaviour can scale well with group size. Given sufficient ambient light, individuals in all sizes of groups (small to large) are expected to independently be able to detect their neighbour's and thus show co-ordinated movement. This expectation is supported by experimental observations of thousand strong starling flocks [@ballerini2008a], schools with ten-hundreds of fish [@tunstrom2013collective], or even humans as we aggregate in small to very large groups [@moussaid2011simple;@dyer2009leadership]. Concrete support for the use of visual cues, and their role in modulating individual decisions in group movement is provided by studies that reconstruct individual sensory *umwelts* [@turner2002encoding;@strandburg2013visual;@belden2019vision]. In contrast to simple models that assume all neighbours in a fixed sensory volume can be detected [@reynolds1987a;@couzin2002a], sensory reconstruction approaches include the details of neighbour positions and visual acuity [@strandburg2013visual;@belden2019vision], and thus allow a detailed analysis of individual sensory inputs and motor outputs. 


## Active sensing in groups : a tricky proposition
Broadly classified, sensory systems are of two types: passive and active. Passive sensing systems such as vision and olfaction are receivers that 'take in' stimuli from the environment. Active sensing animals such as bats, cetaceans, cave swiftlets and weakly electric fish(sensu strictu @nelson2006a) emit pulses of energy and perceive the environment through modulations of this pulse. In this respect, active sensing differs from passive sensing as animals generate their own stimuli to sense the world around them. The fact that animals must constantly emit pulses of energy to detect their surroundings raises cocktail-party like problems for individuals in groups. Electric fish detect objects through fluctuations they cause in the electric field along their body [@heiligenberg2012principles]. When multiple electric fish are in close proximity, they will mutually disrupt each other's ability to detect objects due to the similarity in the emitted electric field properties of individuals [@nelson2006a]. This mutual disruption has been termed 'jamming', inspired by the technical term used in RADAR. Jamming is a common phenomenon expected in all active sensing animals irrespective of the type of energy that forms the probe (sound, electric field, etc.).

In the face of jamming from other active sensing conspecifics or experimental treatments, individuals show 'jamming-avoidance responses' [@watanabe1963change;@bullock1972jamming]. Jamming avoidance response were coined and first reported in weakly electric fish (Gymnotiformes,Mormyridae families). Weakly electric fish 'electrolocate' by emitting electric discharges and detecting the modulations that objects cause to the emitted electric field [@heiligenberg2012principles]. There are two broad types of weakly electric fish: wave-type and pulse-type. Wave-type electric fish continuously emit electric discharges at an individual-specific frequency. When faced with an experimental signal that is close to their own emitted frequency, wave-type fish  shift their discharge frequency to prevent spectral overlap and thus deterioration in electrolocation. The 'pulse' type electric fish emit short electric discharges at intervals. Pulse type electric fish resort to increasing their discharge rate, or adjusting discharges to avoid overlap with interfering experimental pulses [@heiligenberg2012principles]. Studies of jamming avoidance in electric fish have helped form the first glimpses into how active sensing animals deal with jamming. Early studies have primarily focused on individual-level responses to experimental treatments [@heiligenberg2012principles], with recent studies starting simultaneously studying multiple freely swimming electric fish in the laboratory and field are recently on the rise [@arnegard2005electric;@tan2005electrosensory;@donati2016investigation;@henninger2020tracking]. One factor that may alleviate jamming in weakly electric fish is that their electric fields are fairly localised, with individual electrolocation mostly effective till about one body-length [@nelson2006a], and individuals may detect each other's fields at most only a few body lengths away [@knudsen1975spatial].

What about active sensing animals whose energy probes are much less localised, and thus more susceptible to jamming in groups? Echolocating bats emit ultrasonic calls and detect their surroundings by listening for the echoes reflected off objects around them [@griffingalambos1941]. Using the auditory cues in the returning echo such as arrival delay, intensity, and spectral content, bats can detect fine details about the shape, size and texture of obstacles and prey items [@Simmons2014]. The problem of jamming in groups of bats is qualitatively different than in weakly electric fish as the calls and echoes are sound emissions. Sound travels at a speed of around 330m/s (or roughly about 30cm/ms) unlike electric fields that propagate nearly instantaneously at the speed of light. This 

### Echolocation in individual bats
Even though echolocation (much like electrolocation) is somewhat unrelatable to most of us humans^[apart from the human echolocators amongst us], the morphological and physiological basis of hearing in bats is centred around a standard mammalian auditory *bauplan* consisting of a pinna, three ossicles, eardrum, and a cochlea [@neuweiler2000biology]. Bat hearing thresholds match those of humans at around 20$\mu$Pa sound pressure level (SPL) [@Nachtigall2014;@w2007a], and they exhibit many of the same auditory phenomena we do such as spatial unmasking
* hearing capabilities : hearing thresholds, hearing directionality,  Masking - energetic and informational. forward and backward masking. Spatial unmasking,
* call behaviours : call emitted very LOUD!! 

* low duty cycle and high duty-cycle bats

Many species of echolocating bats can be trained to perform psychophysical discrimination tasks, and this has revealed a great depth of knowledge about the similarities and differences

Similar to the two types of electric fish, there are two broad types of echolocating bats : low-duty cycle


### Active sensing in bats and in noise
, an ability to listen to echoes over noise.
1. Griffin's
1. Echolocating bats emit loud calls and listen for echoes --
1. The returning echoes serve as packets of information that the bat uses to gain insights about its surroundings. The time delay, echo level, interference and spectral properties and other blah blah tell the bat more about the objects. 
1. Echolocation might work based on a type of efference copy based mechanism. 
1. 


## The study of group echolocationL
* grand history. starting with spallanzi, moving onto the first 'proof' by Griffin and etc - the focus has always been on how individual bats managed to do stuff. 
* The question of how bats detect echoes in the midst of noise is however not very new. Griffin and the crazy noise room experiment with 50/80? speakers spread all around the room. 
*

* much like electric fish - two types of bats, the low-duty-cycle FM bats like the pulse type, and the high-duty cycle CF-FM bats
* Mostly studies on low duty-cycle FM bats, Both of these species show different responses to 
* Questions of why they do what they do are open 
* CF-FM bats remain understudied due to the difficulty in analysing long overlapping sounds 
* Given that they have lower sensory inputs - how do they manage to show coordinated behaviours in huge groups???

## Technology to the rescue in the study of echolocation
The very discovery of echolocation could only happen because a curious biologist (Donald Griffin) joined a physicist (ZZZZZZZZZZZZZZZZ Pierce) who had developed an ultrasound detector, and pointed it at the inaudible vocalisations of bats [@REFFF]. Without stressing too much on the disciplinary labels of the researchers themselves, the moral of the story is that studying echolocation has always meant closely working with technology and forging inter-disciplinary collaborations. Thankfully technology has moved leaps and bounds since the days of Griffin in the 1950's. Reading an account of Griffin's field work [@griffin1958a] makes one grateful for the multi-functionality of laptops and smartphones. Griffin had to carry oscilloscope, diesel generator, cameras, film rolls, analog tapes and flash lamps to record a few minutes of data in the field. In contrast I've had to carry laptop, digital soundcards and thermal cameras for fieldwork, all of which weigh far less and with the great advantage of being able to record much much more data. 

Some of the challenges still remain the same from Griffin's time onward.  Acoustic tracking of bat calls was first achieved by @aubauer1994dreidimensionale, who used a 4-microphone array. Microphones were placed on a frame, and the time-delays of call arrival between channels were used to triangulate the bat's call position. Since Aubauer's time, multi-microphone arrays have been used to track bats in the lab and field  [@KOBLITZJENSBARBA;@MOSSGHOSE;@SIMMONS;]. Acoustic tracking relies on a knowledge of microphone positions, which is achieved by fixing mic positions on frames. The very array-frames that provide stable positions to the microphones are cumbersome especially in the context of fieldwork. Large multi-mic frames need to be carried, assembled, and aligned each time before recordings begin. Animals may inspect these conspicuous objects, instead of showing their regular echolocation behaviour. There is a strong need for methods that free the researcher from the shackles of classically defined microphone arrays based around simple geometric shapes and configurations on a metal or wooden frame. 

Aside from the 'hardware' issues of placing and managing microphone arrays, certain issues also have also remained the same in the analysis of echolocation data. Automating parameter extraction from echolocation calls is the most scalable and objective method at hand. Manual measurements using spectrogram visualisations of sound for instance can lead to experimenter bias and non-reproducible results [@BRUMMZOLLINGER]. Echolocation researchers have indeed caught up with the digital revolution, 


## Thesis outline 
In this thesis I will investigate the sensory  challenge faced by active sensing animals in groups using a combination of experimental and theoretical methods. Through modelling I will reveal and quantify the sensory challenge FM echolocating bats face in groups of various sizes. I will then present the results of an observational study detailing the echolocation strategies of CF-FM bats in the presence of conspecifics, followed by a novel experimental dataset and workflow to study groups of echolocating bats in the wild. I will end with a series of methodologically driven reports that will significantly reduce the effort needed to perform acoustic tracking at scale, help users simulate the expected performance of their arrays and ease the computational reproduciblity of echolocation call analysis. 

```{r echo=FALSE}
#CPN chapter
```
Echolocation is expected to become increasingly infeasible with growing group sizes due to masking. In response to masking in the form of artificial playbacks and conspecific calls, bats show a variety of changes to their echolocation behaviour. While many experimental studies have reported the changes bats show as 'emitters' of sound, very little focus had been given to date on bats as 'receivers'. Computational work modelling group echolocation has been restricted to models that are qualitatively based on echolocation, with minimal biological details.  In chapter \@ref(cpnchapter) I present an experimentally parameterised computational model that estimates the sensory inputs a bat may receive as it echolocates in a group. The sensory inputs are quantified in terms of the number of echoes detected. Each detected echo corresponds to the detection of one neighbour in the group. I formulate a conceptual framework to estimate echo/neighbour detection in the presence of masking sounds. By quantifying echo detection from small to large groups, I find that even in group sizes of 200 bats, individuals may still be detecting one neighbour every few calls. When alone, a bat detects echoes reflecting off all objects in its surroundings. In contrast to echolocating when alone, bats in groups thus face a much lower 'update rate' in groups. Despite this lowered sensory update rate, I argue that the detection of occasional echoes may provide the sensory basis for the impressive feats of collective behaviour bats show in roosting sites, mating swarms and emergences. 

In Chapter 3 takes us into our first experimental study looking at echolocation in groups of horseshoe bats.  

In Chapter 4 (Uschichka), I do kat kat kat kat. From the time of Griffin & Galambos, who were the first to use the newly invented ultrasonic microphone to record ultrasound calls - the field of echolocation has always been a field that has 'resisted '

Chapter 5 describes a methodology to automatic estimate microphone positions in an acoustic array. Multi-microphone arrays have been an important and indispensable tool in the study of echolocation in the laboratory ever since the work of  @aubauer1994dreidimensionale. Working with microphone arrays in the field however comes with a series of challenges. Handling multi-microphone arrays in the field can be logistically and physically straining: the long cables involved must be brought to order each time, the array frames themselves can be bulky and must be assembled on site each time. The frames themselves are often conspicuous and invite artifactual inspection behaviours from the animals themselves. In certain configurations the positions of each microphone may need to be measured each time the array is setup. While rewarding in terms of the data it generates, the process of setting up a microphone array can be strenuous especially when it comes to taking positional measurements. The use of TotalStation surveying systems that provide direct XYZ measurements are not common in the field (they are themselves another piece of bulky equipment). In contrast to acoustic arrays, camera arrays are much easier to setup and calibrate. Field-friendly protocols like @Theriault2014 mean the field biologist may freely place the cameras, record animal activity and then perform calibrations by moving a common object in front of the cameras. While looking for camera-type calibration workflows, I found the work of @zhayida2016automatic  with their 'Structure-From-Sound' method. @zhayida2016automatic were able to automatically infer microphone positions using only the common sounds recorded across channels as input. I was able to initiate a collaboration with Prof. Åström (Uni. Lund) and convey my enthusiasm for their method when applied to our arrays in the field. This chapter with Prof. Åström and colleagues shows the viability of automatic microphone position estimation in field conditions, using recordings I had made in the Orlova Chuka cave system. This chapter is but a beginning to the development of field-friendly workflows in acoustic tracking. The 'Structure-From-Sound' method used in this chapter and @zhayida2016automatic promise to significantly reduce the barrier to multi-microphone acoustic tracking for bioacousticians. For one it may completely eliminate the need to place microphones in specific geometries on conspicuous bulky frames and secondly, there will be no more need to perform tedious measurements before or after recordings. Being able to handle a larger number of microphones, the bioacoustician is now free to generate even higher resolution measurements of animal sounds. The ease and anticipatory joy of such an effortless acoustic tracking workflow can only be described by the words of a senior colleague^[here's to the encouragement of Lasse Jakobsen] who said knowing there were such methods in development was a 'Christmas gift' in itself.

In Chapter 6 I present the ```tacost``` software package to aid the design and analysis of acoustic tracking systems. The accuracy of acoustic tracking is affected by multiple parameters: array geometry, source sound position, signal-to-noise ratios and the analytical approaches used to process and calculate source sound position itself. Experimental verifications of tracking systems is time and labour intensive, while mathematical analysis of array configurations are by their nature restricted to specific array geometries. Simulated audio data presents a quick and simple method to estimating the real-world performance of acoustic tracking systems either before or after experiments. ```tacost``` generates multi-channel audio data according to user-specified array geometry, source sound and source positions. ```tacost``` can be used to plan array geometry to optimise tracking accuracy before experiments, or post-hoc to estimate the maximal accuracy of the tracking system used. I detail the use of ```tacost``` to estimate patterns in tracking accuracy across space with two types of experimentally used array systems, the planar 'tristar' array with microphones placed regularly on a frame, and an array configuration used in Chapter 4 & 5 with freely-placed microphones spread around a volume. While ```tacost``` does not itself perform any acoustic tracking, it serves as a useful tool to estimate baseline performance for bioacousticians working with acoustic tracking. The package is written in the non-proprietary Python language, and released with an open-source license. To ease its use, the package also has detailed online and offline documentation

In Chapter 7, I present the ```itsfm``` software package originally written to perform the systematic and reproducible analysis of echolocation calls detailed in Chapter 3. CF-FM calls appear like staple-pins when viewed on a spectrogram. The 'rising' and 'declining' portions form the frequency-modulated (FM) parts, while the flat portion, forms the constant-frequency (CF) portion. The two call portions serve different sensory functions, and can be altered independently. To date, studies have adopted a variety of automated and manual methods to segment and then quantify the alterations in the CF and FM call portions. Manual methods of call segmentation are not reproducible and suscept to experimenter bias, while the automated software based methods remain custom scripts whose implementation is briefly detailed in the publications themselves. Publicly available implementations are important for the scrutiny and comparison of published methods. Purely description based implementations can show important differences from original implementations. Additionally, none of the software based methods include assessments of segmentation accuracy. ```itsfm``` implements a commonly described method (that I call the *peak-percentage* method) to segment CF-FM calls, and introduces a new and more reliable method (the *pwvd* method) to segment CF-FM calls. I also create a synthetic dataset of CF-FM calls, and compare the performance of the *peak-percentage* and *pwvd* algorithms in their segmentation accuracy. Results show that the *pwvd* method is overall superior to the *peak-percentage* method, and is thus the recommended algorithm to use for segmenting CF-FM calls. The *pwvd* method, unlike the *peak-percentage* method, is also potentially applicable to vocalisations of any kind as it does not rely on a specific spectro-temporal shape assumption. The ```itsfm``` package is written in the non-proprietary Python language, and released with an open-source license. To ease its use and encourage the further development of the package, detailed online and offline documentation has been made available.