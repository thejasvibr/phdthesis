# General Discussion

We have so far delved into detailed reports of work studying echolocation in groups, and various methodological contributions to the field. In this section I will summarise some broad points of interest, and end with my vision for the future of the field. 

## The 'cocktail party nightmare': a hyperbolic term
In their influential review over a decade ago @ulanovsky2008a coined the term 'cocktail party nightmare' to describe the sensory challenge echolocating bats face in groups. How do individual bats manage to detect their own echoes over the deafening calls of neighbours. How to recognise one's own echoes from the constant stream of others' echoes and calls? In comparison to the cocktail party problems that humans (and perhaps other animals) face, the stakes of not detecting an echo seemed high (collision with obstacles), along with the high sound levels involved. The escalation from *problem* to *nightmare* aptly describes the perceived seriousness of group echolocation. Studies since then revealed a variety of responses that echolocators show in their call behaviour. Bats were well studied as 'emitters' of signals, but understudied as 'receivers'. 

To understand bats as receivers in group echolocation, one must the quantify the extent to which echo detection suffers.I quantified the 'cocktail party nightmare' in great detail for FM bats in Chapter \@(cpnchapter). The results of the model show that when in small groups echo detection is unaffected. With increasing group sizes $\geq$ 30 however, masking plays a progressively stronger role. At group sizes of a 100 bats, a focal bat in the middle of the group can only detect at most one neighbour in front of it. To make it worse, the neighbour is detected too only every third call emission, with no echoes detected two of three times. 

I show in \@ref(cpnchapter) that the sensory inputs individuals have while exhibiting collective motion in active sensing groups is qualitatively and quantitatively different from passive sensing visual groups. Despite occlusion, visually-dominant individuals can detect at least their nearest neighbours. My results showed that in large groups, echolocating bats may not even be able to detect their nearest neighbours every time they call. 
If bats in large groups can only detect their nearest neighbour in front of them occasionally, how do echolocating animal groups show collective movements like milling? @bode2011a provide an answer with their 'limited interactions' model. They show that collective movement emerges even when individuals asynchronously update their own positions with reference to just one neighbour - closely mirroring what may be happening in bat groups. The echo-detection in the model however is based on a simple auditory model - that did not include dynamic information processing (integration over multiple echoes), temporal gating or attentional processes.  The results from the model are thus lower bound estimates of what a real echolocator may experience, and questions the severity of the problem that bats may experience in groups. In the light of results from my model,  I now wonder whether for bats in groups the cocktail party is more of a 'challenge' than a nightmare?

## Group echolocation need not always be taxing
The experimental study of group echolocation is centred around the echolocation responses individuals show to groups or experimental playbacks. In Chapter \@(hbcchapter) I investigated how CF-FM bats alter their echolocation when alone or in groups. The CF-FM bats in our study did not show major changes in their echolocation across group size. One call parameter even matched simulations recreating independent (non-responsive) group echolocation. 

In contrast to many other studies, including one related species, why did our bats show no response? The lack of a 'response' informs us about our expectations. Much like how I questioned the severity of FM bat group echolocation in Chapter \@ref(cpnchapter)- these results also question the problem of call-echo overlap. When flying to a roosting site, it is highly unlikely that CF-FM bats will listen to echoes from their long CF component. Individual bats are more likely to be processing the tFM component's echoes, which provides distance information. The tFM components are short (few milliseconds) and occupy a different range of frequencies from the CF component. The multi CF-FM bat (1-4 bats) flights in our data is thus equivalent to a group of upto four FM bats echolocating together. The results of Chapter \@ref(cpnchapter) tell us clearly that echo-detection is not affected at group sizes below 10 bats. Another very important reason bats may have shown no response is the high directionality of call emission in CF-FM bats, which are much more directional than FM bat calls. Intuitively, it would seem that a group of highly directional echolocators may fare better than a group of wide-beam echolocators - though this remains to be verified by modelling. 

Ultimately though, it is important to stress that we studied resident bats that were likely very familiar with the cave's structure. Bats integrate echo information from multiple calls, and in combination with spatial memory - this makes for a system that is robust to occasional 'drops' in echo detection. Aside from being tolerant of drops in echo-detection, bats in flightroom studies in fact reduce their call rate with time spent in the space [@chen2015variation;@yamada2020modulation]. The two factors, multi-call integration and dropping call rate indicates a scenario where bats do not necessarily need constant echo inputs to find their way in familiar environments. 

Field studies provide a good setting to quantify the full plethora of behaviours that animals show in 'real-life' conditions.
Our negative result highlights the importance of studying group echolocation in a natural setting, and adds 'no response' to the variety of responses shown by bats in groups. 

## *Ushichka*: a model dataset for group active sensing
In Chapter \@ref(ushichkachapter) I report my contribution to pushing the frontiers in the study of experimental group echolocation. Group echolocation in the field has been studied either in small groups (2-3 bats), or solely with audio or video. Animals in groups interact with each other, while also responding to the presence of their physical surroundings - like the trees, rocks or walls of a cave. Studies to date have ignored the physical environment, and only been centred on the bats themselves. Data on the simultaneous echolocation and flight behaviours of bats placed in their natural context is lacking. Having such multi-modal data provides exciting insights into the sensory inputs individuals receive, and the motor outputs they perform as a result. The trajectory and call data from *Ushichka* will allow us to recreate the dynamic sensory inputs of each individual in a group. The position and call timings of individuals can be used in simulations of sound propagation to reconstruct the echo and call arrival times from neighbours, and cave surfaces. 

While Chapter \@ref(cpnchapter) recreated the sensory inputs of a bat in a group *in silico*, *Ushichka* provides us access to the sensory inputs of bats in a group *in caverna*!. Having reconstructed the sensory inputs of bats in a group, we can then understand the sensorimotor heuristics that govern their collective motion. The collective motion and echolocation of bat groups has only been quantified in the impressive emergence behaviours of *T. brasiliensis* to date [@theriault2010a]. The *T.brasiliensis* studies provide a series of findings that remain unreconciled. The bats emit extremely long calls ($\geq$ 6 ms) in these dense emergences [@gillam2010a], despite flying somewhat close to their neighbours  (~0.5m inter-neighbour distance) [@theriault2010a]. This close-distance flight with long duration calls means their own emitted calls will mask returning echoes. *T. brasiliensis* emergences occur around sunset like in many other species, and vision is another potential sensory modality in use. Given the call-echo masking and potential use of vision, to what extent is echolocation really being used by animals in these groups? *Ushichka* provides a somewhat 'cleaner' dataset into how echolocation is used in bat groups flying under pitch-black conditions of a cave system. 

The bright vs dark conditions of sunset emergences and in-cave flights also brings up the question of how different the behavioural heuristics of 'multi-modal' (vision+echolocation) emerging bats are to 'uni-modal' (only echolocation) bats in caves or dark-conditions. Can emerging bats fly at much higher densities because they can also rely on vision, or are they in fact flying at higher densities because it improves neighbour detection for echolocation (as shown in Chapter \(cpnchapter)), and perhaps vision as well? Computational modelling that combines sensory inputs from both vision and echolocation [eg. @bar2015sensory] of group flights is one way to forward to disentangle the contributing factors.

*T. brasiliensis* emergences are indeed a wonder of nature, though I think we are still technologically limited in our ability to analyse the high call densities and call overlap in the audio. I believe the call densities in  *Ushichka* on the other hand lie in the 'Goldilocks zone' of today's technology - we are neither too far from its capabilities, nor too easily handled by regular routines. I look forward to *Ushichka* becoming a centre of active inter-disciplinary collaboration, and a reference dataset for many new methodological innovations in image and signal processing, acoustic tracking and echolocation.

## Lowering the logistical and technical barriers to (group) echolocation
In Chapters \@ref(sfscotdoa),\@ref(tacostchapter) and \@ref(itsfmchapter) I presented a series of methods that promote the accuracy, automation, and ease with which echolocation in general can be studied. The ```itsfm``` package adds the 'pwvd' method, a new method to segment CF-FM bat calls accurately and contributes a reference implementation for a previously described method. ```tacost``` allows bioacousticians to assess the performance of their system after data collection, or optimise in the planning phase. Both packages are released under an open-source license and with detailed online documentation. The two packages are but a beginning in what I hope will be a wave of open-source bioacoustics and specifically, echolocation related packages. There still seems to be an inertia in the echolocation community when it comes to releasing code. Even though many studies perform acoustic tracking, to my knowledge there remain little published details on the software implementationss. The software behind the acoustic tracking is often either closed-source, or a collection of inhouse scripts with limited documentation. Both closed-source code and inhouse scripts are not welcoming of newcomers in the research community, who may not have access to the people concerned. The research field itself suffers with the continuous use of old, unmaintained code. It is my hope that by contributing area-specific  software tools for echolocation researchers, the echolocation community may grow to realise the utility and value of openly-available packages.

In Chapter \ref(@sfscotdoa), I present the results of a collaboration towards an frame-less, measurement-free approach to acoustic tracking. In the 'Structure-from-Sound' framework used in Chapter \@ref(sfscotdoa), a series of common sounds are first recorded by all microphones. The time-difference-of-arrivals across channels are then used to infer microphone positions. In many ways, this new method is the first such application to the field of echolocation, and promises a great reduction in the time spent setting up an array, and the weight of equipment to be carried into the field. I discuss more on the potential of this method in \@ref(threepronged).

## The future of group active sensing research 

### Group active sensing in 'other' animals {#parametrising}
The entirety of this thesis has been dedicated to the study of laryngeal-echolocating bats that emit calls between 1-100 ms long. These calls typically have a discernible spectro-temporal structure (FM/CF). What about other types of echolocators?
Oilbirds, swiftlets, certain fruit bats and other odontocete echolocators come to mind. Odontocetes and two species of fruit bats (*Rousettus aegyptiacus* and *R. leschenaulti*) emit very short 'clicks' about tens to hundreds of microseconds long [@Fenton2014]. The probability of call-echo overlap is proportional to the duration of the calls being emitted in a group [@beleyur2019modeling], and in this sense, click-based echolocators are unlikely to suffer problems detecting echoes because of call-echo (or click-echo) overlaps. Oilbirds and swiflets also emit clicks, but these clicks are much closer in duration to bat echolocation calls, ranging from a one to tens of milliseconds [@brinklov2013echolocation] - making them much more likely to suffer call-echo overlaps like bats in groups.

How click based echolocators manage to recognise their own echoes from the echoes of others is an interesting question that I think is particularly worth pursuing in the future. One strategy echolocating bats may use to recognise their own echoes is the presence of unique vocal signatures or 'voices' [@yovel2009voice;@masters1995sonar] in their echolocation calls. Clicks are defined by the apparent absence of spectro-temporal structure [@pye1980echolocation], and their impulse-like structure (much like the clapping of the hand, or a hammer hitting a surface). Given their generally short durations I wonder if clicks carry individual-specific signatures. Of course, the absence of a 'voice' in click-based echolocation doesn't preclude the use the other mechanisms that all echolocators use, such as temporal gating (using echoes that arrive within an expected time window) or using directional cues to filter out off-target echoes arriving from behind or the sides. 

As receivers, all groups of active sensing echolocators known to date (birds and mammals) are likely to face the common problem of masking. Evidence for the occurence of masking is not new, but systematic tests in the context of echolocation have only been done in laryngeal-echolocating bats and odontocetes [@Nachtigall2014]. Most discussions of masking in echolocation have typically been centred around one type of masking, *energetic* masking. Energetic masking is a physiologically driven phenomena where the intensity of louder sounds suppresses the detection of fainter sounds [@yost2007a]. Another, less discussed type of masking is *informational* masking. Informational masking occurs when signal detection is affected, despite the absence of energetic masking (no temporal or spectral overlap) [@yost2007a]. For instance, humans experience informational masking when trying to listen to a sentence with unrelated words in between [@TOCOMPLETE]. Unlike energetic masking that occurs primarily at the cochlear level, informational masking is thought to occur due to the interplay of attention and other higher-order phenomena [@TOCOMPLETE]. To my knowledge, there remain no studies of informational masking in echolocating animals - and this presents a yet unexplored facet in the study of individual and group echolocation. Here, I see the scope for the next wave of multi-species phantom echo studies [eg. @SURLYKKe;@SIMMONS;] whose results can be directly used to construct 'masking functions' (sensu @beleyur2019modeling). Echolocating bats vary in the continuum of group sizes that they live in [@ECOLOGYOFBATS], and this means the extent of masking that they are likely to experience from conspecifics will also vary. Does this typical group-size based masking have an effect on the actual ability of individuals to detect echoes in noise? It may also be that the robustness of echolocation to noise is more strongly affected by the environmental clutter and reverberance, rather than roosting group size per se.  Studying a wider variety of species will allow us to explore the ecological and evolutionary basis of masking tolerance. 

As emitters, active sensing animals choose how and where to focus their probe's energy [@Fenton2014]. Bats and odontocetes narrow or widen the 'beam shape' of their emissions depending on the behaviour at hand. In essence, individuals choose to 'focus' or 'zoom out' their perceptual field. All beam shape studies I know of have quantified beam shapes and their modulation in solitary animals. A classic result is of bats emitting wide beam-shapes while searching for prey, narrowing onto the prey while approaching, and 'zooming out' just before prey interception [@Fenton2014]. The direction and width of the emitted calls are direct pointers of where an animal is focussing its sensory efforts. The spatial aspects of echolocation in groups remain an area of pure speculation. Do animals emit wide beams to maximise their sensory volume - and pay the costs of mutual interference? Or do they emit narrow beams focussing on the nearest objects around them - at the risk of sudden collision with an object barely out-of sensory range? Call overlaps and small microphone arrays have hindered beam-shape reconstruction in multi-animal groups. At least in click-emitting echolocators, where overlaps may not pose a problem - beam shape modulations in groups represents a fascinating and tractable model system. Large multi-microphone arrays like in the *Ushichka* dataset (or perhaps even more channels may be required!) are the future to study the spatial aspects of signal emission. 

### The three-pronged approach to solve the inverse problem of group active sensing  {#threepronged}
The study of biological problems is full of inverse problems. We observe a range of fascinating phenomena, but often are unable to (and perhaps will never be able to!) recreate them under controlled settings. In this respect, biological, geological and cosmological phenomena must be tackled with a synergetic approach involving 1) pushing new technologies to generate improved measurements, 2) performing scaled-down experiments wherever possible, and finally 3) formulating computational/theoretical models that explain and predict details of the phenomenon.

In the case of active sensing, new technologies promise to lower the barrier for entry into acoustic tracking. In this thesis itself [Chapter \@ref(sfscotdoa)], we see the larval form of a field-friendly  workflow for mic position self-calibration. In its more developed form, this workflow will closely mirror current camera array calibration workflows (eg. @Theriault2014). The bioacoustician only needs to arrive at the field site, setup the microphones unobtrusively in the recording volume. To later infer the microphone positions, playbacks with a small speaker may be necessary (the animal vocalisations could themselves be used instead!). The ease and anticipatory joy of such an effortless acoustic tracking workflow can only be described by the words of a senior colleague^[here's to the encouragement of Lasse Jakobsen] who said knowing there were such methods in development was the year's 'Christmas gift'.

Multi-channel microphone arrays are of course typically associated with reams of cables extruding from the soundcard leading to the microphones. Cables need constant maintenance, and can in my experience, contribute to a considerable portion of weight during field work. In the future, I see the scope for either wireless multi-channel recording systems, or more strategically, the potential for acoustic tracking with many independently recording devices. Acoustic tracking needs accurate time-difference of arrivals, and this has always been done so far using multi-channel soundcards that digitise data synchronously for all channels. In principle however, time-difference-of-arrivals may also be measured across two unsynchronised channels as long as the temporal offset between them is known. Similar to microphone position self-calibration, recent methods to estimate offset between asynchronous channels post-hoc  [@burgess2012node;@burgess2013minimal] promise the next methodological advance to the bioacoustician in the field. Acoustic tracking may then be done with with many smaller, cheaper and more portable recording devices. A future workflow may even include placing hundreds to thousands of hand-held recorders in a cave, recording data, and then finally performing playbacks for cross-device synchronisation and position calibration. Groups of bats necessarily mean more complexity in the analysis of the associated data. Computer vision algorithms have made great strides into animal movement tracking, and software to reliably track hundreds to thousands of individuals is in place. On the other hand, there is much opportunity for methodological developments in the analysis complex audio data with overlapping sounds and match the same calls across multiple channels.

I use the term 'scaled-down' experiment to mean any attempt at estimating animal capabilities under relatively controlled conditions. As described in \@ref(parametrising), many aspects of the hearing capabilities of bats and other animals remain unknown. My own experience with parametrising the computational model in Chapter @cpnchapter has shown me the value of comparable experimental protocols, and even more, of multi-species studies with the same protocol. The psychophysics of only a handful of temperate and tropical bat species (*E. fuscus*,*P.pipistrellus*,*P.discolor*, *M. lyra*) have been characterised, despite the high speciosity of bats. In flightroom studies too, a uniform protocol across species will allow for direct comparisons of results. Continued exploration of the latest animal-tracking techniques with growing group sizes in flightrooms will provide a performance benchmark of the available techniques. The behavioural responses observed in flightrooms may then form the focus of field observations of much larger groups.

With inverse problems, modelling provides us a way to explore the feasibility of the proposed mechanism, and "revise our thinking about the processes occuring" [@otto2011biologist]. Despite the constant focus on sensory systems in this thesis, it is important to remember that active sensing animals are not merely 'sensors'. Echolocating bats are living, breathing animals that perform rapid, well co-ordinated *behaviours* using the sensory inputs they receive. Bats exhibit a host of fascinating behaviours using echolocation, including catching prey, fly long distances, care for their young, among which group flight is perhaps the most tantalising to piece-together conceptually. The bystander bioacoustician watching a  mating swarm of a few hundred bats flying in a cave is only occupied by the many reasons this shouldn't even be possible in the first place!  How can collective behaviours like swarming or cave emergence occur, despite the limited sensory inputs individuals receive about their neighour positions? For that matter, given the sophistication of bat echolocation in experimental noise, does an individual bat actually even perceive a drop in sensory input rate? Models of group echolocation [eg. Chapter \@ref(cpnchapter),@mazar2020sensorimotor] rely on the input data used to parametrise them, which are often scarce. Even existing models when parametrised with new data may reveal a much more nuanced picture. Modelling may reveal that echo detection in groups occurs well, but the sensory challenge is attentional [@lemasson2009], ie. to choose the most relevant one in the shortest possible time to avoid collision. Even if bats are capable of tracking the positions of all of their neighbours in a group, may be they only respond to the closest one - much like the collision-avoidance heuristic shown in @vanderelst2015sensorimotor. 

The three-pronged approach advocated above is of course no task for a single investigator working all alone. The approach involves a dedicated back-and-forth between disciplinary ideas, methods and people. It is my hope to have provided a cursory glimpse in this thesis of the contributions it can bring. How active sensing animals aggregate and perform impressive feats is an exciting problem that has occupied and will continue to occupy many of us in the years to come. Meanwhile, unphased by their own abilities, the bats, they carry on effortlessly circling around an invisible centre in pitch-black caves and emerging in smoke-like streams in the light of the setting sun.





