<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter6 tacost: Testing and simulating the performance of acoustic tracking systems | Beleyur-Thesis</title>
  <meta name="description" content="A thesis" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter6 tacost: Testing and simulating the performance of acoustic tracking systems | Beleyur-Thesis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A thesis" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter6 tacost: Testing and simulating the performance of acoustic tracking systems | Beleyur-Thesis" />
  
  <meta name="twitter:description" content="A thesis" />
  

<meta name="author" content="Thejasvi Beleyur" />


<meta name="date" content="2020-11-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="robust-self-calibration-of-constant-offset-time-difference-of-arrival.html"/>
<link rel="next" href="itsfm.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />



<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Zusammenfassung</a></li>
<li class="chapter" data-level="" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.0.1" data-path="introduction.html"><a href="introduction.html#animal-communication-often-consists-of-public-signals."><i class="fa fa-check"></i><b>1.0.1</b> Animal communication often consists of public signals.</a></li>
<li class="chapter" data-level="1.0.2" data-path="introduction.html"><a href="introduction.html#listening-in-the-noise"><i class="fa fa-check"></i><b>1.0.2</b> Listening in the noise</a></li>
<li class="chapter" data-level="1.0.3" data-path="introduction.html"><a href="introduction.html#active-sensing-animals-and-listening-in-the-noise"><i class="fa fa-check"></i><b>1.0.3</b> Active sensing animals and listening in the noise</a></li>
<li class="chapter" data-level="1.0.4" data-path="introduction.html"><a href="introduction.html#active-sensing-in-bats-and-in-noise"><i class="fa fa-check"></i><b>1.0.4</b> Active sensing in bats and in noise</a></li>
<li class="chapter" data-level="1.0.5" data-path="introduction.html"><a href="introduction.html#group-echolocation-as-a-serious-sensory-challenge"><i class="fa fa-check"></i><b>1.0.5</b> Group echolocation as a serious sensory challenge</a></li>
<li class="chapter" data-level="1.0.6" data-path="introduction.html"><a href="introduction.html#implications-of-group-echolocation-on-collective-behaviour"><i class="fa fa-check"></i><b>1.0.6</b> Implications of group echolocation on collective behaviour</a></li>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#thesis-outline"><i class="fa fa-check"></i><b>1.1</b> Thesis outline</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><i class="fa fa-check"></i><b>2</b> Modeling active sensing in groups of bats reveals echo detection even in large groups</a><ul>
<li class="chapter" data-level="" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#cpn_abstract"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#introduction"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#materials-and-methods"><i class="fa fa-check"></i><b>2.2</b> Materials and methods</a><ul>
<li class="chapter" data-level="2.2.1" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#model-scenarios"><i class="fa fa-check"></i><b>2.2.1</b> Model Scenarios</a></li>
<li class="chapter" data-level="2.2.2" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#model-implementation"><i class="fa fa-check"></i><b>2.2.2</b> Model Implementation</a></li>
<li class="chapter" data-level="2.2.3" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#model-parametrization"><i class="fa fa-check"></i><b>2.2.3</b> Model Parametrization</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#results"><i class="fa fa-check"></i><b>2.3</b> Results</a><ul>
<li class="chapter" data-level="2.3.1" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#effect-of-group-size-on-neighbor-detection"><i class="fa fa-check"></i><b>2.3.1</b> Effect of Group Size on Neighbor Detection</a></li>
<li class="chapter" data-level="2.3.2" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#effect-of-call-parameters-group-geometry-and-acoustic-parameters-on-neighbor-detection"><i class="fa fa-check"></i><b>2.3.2</b> Effect of Call Parameters, Group Geometry, and Acoustic Parameters on Neighbor Detection</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#discussion"><i class="fa fa-check"></i><b>2.4</b> Discussion</a><ul>
<li class="chapter" data-level="2.4.1" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#improved-echo-detection-in-real-world-situations"><i class="fa fa-check"></i><b>2.4.1</b> Improved Echo Detection in Real-World Situations</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#conclusion"><i class="fa fa-check"></i><b>2.5</b> Conclusion</a><ul>
<li class="chapter" data-level="2.5.1" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#acknowledgements"><i class="fa fa-check"></i><b>2.5.1</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#supplementary-information"><i class="fa fa-check"></i><b>2.6</b> Supplementary Information</a><ul>
<li class="chapter" data-level="2.6.1" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#model-parametrization-1"><i class="fa fa-check"></i><b>2.6.1</b> Model parametrization</a></li>
<li class="chapter" data-level="2.6.2" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#model-implementation-1"><i class="fa fa-check"></i><b>2.6.2</b> Model implementation</a></li>
<li class="chapter" data-level="2.6.3" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#open-source-software-used-in-the-research"><i class="fa fa-check"></i><b>2.6.3</b> Open-source software used in the research</a></li>
<li class="chapter" data-level="2.6.4" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#acknowledgements-1"><i class="fa fa-check"></i><b>2.6.4</b> Acknowledgements</a></li>
<li class="chapter" data-level="2.6.5" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#supplementary-schematics-tables-and-figures"><i class="fa fa-check"></i><b>2.6.5</b> Supplementary Schematics, Tables and Figures</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="horseshoe-bat-craziness-paper.html"><a href="horseshoe-bat-craziness-paper.html"><i class="fa fa-check"></i><b>3</b> Horseshoe bat craziness paper</a></li>
<li class="chapter" data-level="4" data-path="ushichka.html"><a href="ushichka.html"><i class="fa fa-check"></i><b>4</b> ushichka</a><ul>
<li class="chapter" data-level="4.1" data-path="ushichka.html"><a href="ushichka.html#example-one"><i class="fa fa-check"></i><b>4.1</b> Example one</a></li>
<li class="chapter" data-level="4.2" data-path="ushichka.html"><a href="ushichka.html#example-two"><i class="fa fa-check"></i><b>4.2</b> Example two</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="robust-self-calibration-of-constant-offset-time-difference-of-arrival.html"><a href="robust-self-calibration-of-constant-offset-time-difference-of-arrival.html"><i class="fa fa-check"></i><b>5</b> Robust Self-Calibration of Constant Offset Time-Difference-of-Arrival</a><ul>
<li class="chapter" data-level="" data-path="robust-self-calibration-of-constant-offset-time-difference-of-arrival.html"><a href="robust-self-calibration-of-constant-offset-time-difference-of-arrival.html#sfsabstract"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="5.1" data-path="introduction.html"><a href="introduction.html#introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="robust-self-calibration-of-constant-offset-time-difference-of-arrival.html"><a href="robust-self-calibration-of-constant-offset-time-difference-of-arrival.html#time-difference-of-arrival-self-calibration"><i class="fa fa-check"></i><b>5.2</b> Time-difference-of-arrival self calibration</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="tacost-testing-and-simulating-the-performance-of-acoustic-tracking-systems.html"><a href="tacost-testing-and-simulating-the-performance-of-acoustic-tracking-systems.html"><i class="fa fa-check"></i><b>6</b> <code>tacost</code>: Testing and simulating the performance of acoustic tracking systems</a><ul>
<li class="chapter" data-level="" data-path="tacost-testing-and-simulating-the-performance-of-acoustic-tracking-systems.html"><a href="tacost-testing-and-simulating-the-performance-of-acoustic-tracking-systems.html#tacostabstract"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="6.1" data-path="introduction.html"><a href="introduction.html#introduction"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="tacost-testing-and-simulating-the-performance-of-acoustic-tracking-systems.html"><a href="tacost-testing-and-simulating-the-performance-of-acoustic-tracking-systems.html#statement-of-need"><i class="fa fa-check"></i><b>6.2</b> Statement of need</a></li>
<li class="chapter" data-level="6.3" data-path="tacost-testing-and-simulating-the-performance-of-acoustic-tracking-systems.html"><a href="tacost-testing-and-simulating-the-performance-of-acoustic-tracking-systems.html#design"><i class="fa fa-check"></i><b>6.3</b> Design</a></li>
<li class="chapter" data-level="6.4" data-path="tacost-testing-and-simulating-the-performance-of-acoustic-tracking-systems.html"><a href="tacost-testing-and-simulating-the-performance-of-acoustic-tracking-systems.html#examples"><i class="fa fa-check"></i><b>6.4</b> Examples</a><ul>
<li class="chapter" data-level="6.4.1" data-path="tacost-testing-and-simulating-the-performance-of-acoustic-tracking-systems.html"><a href="tacost-testing-and-simulating-the-performance-of-acoustic-tracking-systems.html#localisation-accuracy-of-the-tristar60-system"><i class="fa fa-check"></i><b>6.4.1</b> Localisation accuracy of the tristar60 system</a></li>
<li class="chapter" data-level="6.4.2" data-path="tacost-testing-and-simulating-the-performance-of-acoustic-tracking-systems.html"><a href="tacost-testing-and-simulating-the-performance-of-acoustic-tracking-systems.html#localisation-accuracy-of-a-multi-microphone-array-in-the-field"><i class="fa fa-check"></i><b>6.4.2</b> Localisation accuracy of a multi-microphone array in the field</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="tacost-testing-and-simulating-the-performance-of-acoustic-tracking-systems.html"><a href="tacost-testing-and-simulating-the-performance-of-acoustic-tracking-systems.html#future-directions"><i class="fa fa-check"></i><b>6.5</b> Future directions</a></li>
<li class="chapter" data-level="6.6" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#acknowledgements"><i class="fa fa-check"></i><b>6.6</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="itsfm.html"><a href="itsfm.html"><i class="fa fa-check"></i><b>7</b> itsfm</a><ul>
<li class="chapter" data-level="7.1" data-path="ushichka.html"><a href="ushichka.html#example-one"><i class="fa fa-check"></i><b>7.1</b> Example one</a></li>
<li class="chapter" data-level="7.2" data-path="ushichka.html"><a href="ushichka.html#example-two"><i class="fa fa-check"></i><b>7.2</b> Example two</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#conclusion"><i class="fa fa-check"></i><b>8</b> Conclusion</a></li>
<li class="chapter" data-level="9" data-path="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html"><a href="modeling-active-sensing-in-groups-of-bats-reveals-echo-detection-even-in-large-groups.html#acknowledgements"><i class="fa fa-check"></i><b>9</b> Acknowledgements</a></li>
<li class="chapter" data-level="10" data-path="author-contributions.html"><a href="author-contributions.html"><i class="fa fa-check"></i><b>10</b> Author contributions</a></li>
<li class="chapter" data-level="11" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>11</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Beleyur-Thesis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tacost-testing-and-simulating-the-performance-of-acoustic-tracking-systems" class="section level1">
<h1><span class="header-section-number">Chapter6</span> <code>tacost</code>: Testing and simulating the performance of acoustic tracking systems</h1>

<p>This chapter was published as a preprint on <em>biorXiv</em>:</p>
<p><em>Beleyur, T. (2020). <code>tacost</code>: Testing and simulating the performance of acoustic tracking systems. bioRxiv.</em></p>
<div style="page-break-after: always;"></div>
<div id="tacostabstract" class="section level2 unnumbered">
<h2>Abstract</h2>
<p><code>tacost</code> is a Python package to allow the testing of acoustic tracking systems. While many microphone array systems have been characterised analytically and experimentally - these are time-intensive methods. <code>tacost</code> provides a simulation based framework to rapidly assess the tracking behaviour of multiple array geometries, and the dissection of other relevant parameters. This paper explains briefly the design of the package and highlights two example use cases in which the tracking accuracy of different microphone geometries are characterised.</p>
<div style="page-break-after: always;"></div>
</div>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">6.1</span> Introduction</h2>
<p>Acoustic tracking is a common method used to study vocalising animals such as birds, bats and cetaceans <span class="citation">(Suzuki et al. <a href="#ref-suzuki2017harkbird" role="doc-biblioref">2017</a>; Aubauer <a href="#ref-aubauer1996acoustical" role="doc-biblioref">1996</a>; Møhl et al. <a href="#ref-mohl2000sperm" role="doc-biblioref">2000</a>; Hügel et al. <a href="#ref-Hugel2017" role="doc-biblioref">2017</a>; Holderied and Von Helversen <a href="#ref-Holderied20032293" role="doc-biblioref">2003</a>; Rhinehart et al. <a href="#ref-rhinehart2020a" role="doc-biblioref">2020</a>; Blumstein et al. <a href="#ref-blumstein2011a" role="doc-biblioref">2011</a>)</span>.
Using acoustic tracking, biologists can detect the position of the animal and track it through space as it moves over time. The localisation accuracy of an acoustic tracking system depends on a variety of factors. There are <em>internal</em> factors such as microphone array geometry, signal processing routines, and the mathematical formulations used to localise sounds (time-of-arrival, time-of-arrival-difference, angle-of-arrival, power-steering). The <em>external</em> factors include aspects related to the actual signal itself, ie. signal-to-noise ratio, and spectro-temporal properties of the emitted sound (noise, linear/hyperbolic sweep) <span class="citation">(Wahlberg <a href="#ref-Wahlberg1999" role="doc-biblioref">1999</a>)</span>.
While experiments and analytical modelling may be the definitive way to determine a tracking system’s end accuracy, simulations allow a quick and systematic method to estimate the source of tracking errors. <code>tacost</code> provides a flexible workflow to manipulate and study the effect of both internal and external factors. <code>tacost</code> generates audio files for source positions and array geometries specified by the user. This allows the user to analyse the efficacy of their tracking system’s baseline performance.</p>
</div>
<div id="statement-of-need" class="section level2">
<h2><span class="header-section-number">6.2</span> Statement of need</h2>
<p>Generating simulated audio for a set of source sounds, positions and a given array configuration is a relatively simple task. However, to this my knowledge, there are no publicly available, tested and documented packages for this task published to date. Codebases that are publicly available have the advantage of being used by a larger user-base and can thus benefit from bug discoveries much faster than in-house or individually written one-time use scripts. <code>tacost</code> provides a robust and well-documented software workflow <span class="citation">(Taschuk and Wilson <a href="#ref-Taschuk2016" role="doc-biblioref">2016</a>)</span> with user and developer friendly documentation <a href="https://tacost.readthedocs.io/en/latest/">hosted online</a>. <code>tacost</code> contributes to the Python scientific ecosystem in the hope of promoting the growth of acoustics and bioacoustic research in open-source languages like Python. In particular, <code>tacost</code> will help researchers working in the field of acoustics and bio-acoustics <span class="citation">(Framond-Bénard et al. <a href="#ref-deframond2020" role="doc-biblioref">2020</a>)</span> plan and examine the behaviour of their acoustic tracking systems.</p>
</div>
<div id="design" class="section level2">
<h2><span class="header-section-number">6.3</span> Design</h2>
<p>The design of <code>tacost</code> focusses on a reproducible and user-friendly method <span class="citation">(Wilson et al. <a href="#ref-Wilson2012" role="doc-biblioref">2012</a>)</span> to generate WAV files that form the input for acoustic tracking softwares. Users may interact with <code>tacost</code> through custom-written Python scripts
by calling it as a Python package with <code>import tacost</code> or in the ‘no-coding’ mode. The ‘no-coding’ mode is especially suitable for users unfamiliar with Python. The no-coding mode is based around a parameter file that is used to specify various parts of the WAV file to be created.
Through the parameter file the user can specify the emitted sound, source positions, inter-sound-intervals, sampling rate and other relevant variables to customise the test scenario.</p>
</div>
<div id="examples" class="section level2">
<h2><span class="header-section-number">6.4</span> Examples</h2>
<p>The localisation accuracy of a microphone array may not be uniform over 3D space <span class="citation">(Aubauer <a href="#ref-aubauer1996acoustical" role="doc-biblioref">1996</a>; Wahlberg <a href="#ref-Wahlberg1999" role="doc-biblioref">1999</a>)</span>. This accuracy is independent of the actual signal and recording conditions of the input data, but rather dependent on the array geometry and mathematical formulations used to record and calculate sound source position.</p>
<p>The accuracy of a few microphone array configurations has been characterised analytically <span class="citation">(Aubauer <a href="#ref-aubauer1996acoustical" role="doc-biblioref">1996</a>)</span> and experimentally <span class="citation">(Wahlberg <a href="#ref-Wahlberg1999" role="doc-biblioref">1999</a>)</span>. While reflecting the system’s capabilities, analytical
and experimental characterisations are often time-intensive. In contrast, simulation uncovers the intrinsic accuracy of an array relatively quickly through the use of audio files with simulated emission points spread across the recording volume of interest.
<code>tacost</code> can be used to characterise the maximal localisation accuracy of an acoustic tracking system with novel array geometries and recording scenarios. In Example 1, I show how <code>tacost</code> can be used to verify known trends in
localisation error with the tristar60, a commonly used array system. In Example 2, I show how <code>tacost</code> can be used to estimate the expected localisation error in a multi-microphone array with a novel and field-friendly geometry.</p>
<div id="localisation-accuracy-of-the-tristar60-system" class="section level3">
<h3><span class="header-section-number">6.4.1</span> Localisation accuracy of the tristar60 system</h3>
<p>The tristar60 array is a commonly used array geometry <span class="citation">(Aubauer <a href="#ref-aubauer1996acoustical" role="doc-biblioref">1996</a>; Holderied and Von Helversen <a href="#ref-Holderied20032293" role="doc-biblioref">2003</a>; Hügel et al. <a href="#ref-Hugel2017" role="doc-biblioref">2017</a>; Lewanzik and Goerlitz <a href="#ref-Lewanzik2018" role="doc-biblioref">2018</a>)</span> with 4 microphones in a plane on an inverted T array. Three peripheral microphones are placed 120<span class="math inline">\(^{\circ}\)</span> to
each other at 60 cm distance from the central mic on the inverted T-array. A series of emission points spanning the upper right quadrant of the array were simulated. The emitted sound was set to a linear sweep.</p>
<p>The output WAV files from <code>tacost</code> were run through the TOADSuite package <span class="citation">(Goerlitz <a href="#ref-holger_toadsuite_manual" role="doc-biblioref">2019</a>; Stilz, Koblitz, and Goerlitz <a href="#ref-toadsuite_peterstilz" role="doc-biblioref">2019</a>; Hügel et al. <a href="#ref-Hugel2017" role="doc-biblioref">2017</a>; Lewanzik and Goerlitz <a href="#ref-Lewanzik2018" role="doc-biblioref">2018</a>)</span>, a software package that localises sounds using the time-of-arrival-differences across channels. ) shows the localisation accuracy map
for the tristar60 microphone array. It can be seen (Figure ) that localisation error increases with increasing radial distance from the central microphone, and remains &lt;7<span class="math inline">\(\%\)</span> of the radial distance.</p>

</div>
<div id="localisation-accuracy-of-a-multi-microphone-array-in-the-field" class="section level3">
<h3><span class="header-section-number">6.4.2</span> Localisation accuracy of a multi-microphone array in the field</h3>
<p>While recording in the field, it may be difficult to use fixed arrays mounted on stands. Arrays on stands are difficult to carry and may also influence the behaviour of the animals being recorded. It is thus advantageous to use less obtrusive micorphone geometries, for instance by placing microphones are placed on pre-existing structures such as the walls of a cave or trees. These microphone geometries are field-friendly, but their localisation accuracy is hard to characterise analytically. <code>tacost</code> is an ideal tool to explore the tracking performance of such flexibly placed microphone arrays. (Figure ) shows the microphone array geometry and recording system described in <span class="citation">(Batstone et al. <a href="#ref-Batstone2019" role="doc-biblioref">2019</a>)</span>. In short, the array consisted of 11 microphones, 4 of them on a 120cm tristar, and the remaining 7 microphones attached to the walls of a cave. A series of sound emission points were created simulating points in the volume enclosed by the array. The points matched the volume echolocating bats flew within. The simulated sound was set to a linear sweep, which mimicked that of a bat call. The <code>tacost</code> output WAV files were analysed with the TOADSuite. The resulting accuracy map reveals that overall, the localisation error is between 7-30 centimetres for the given emission points. This corresponds to a maximum error of upto 30cm in tracking the position, and of upto 19<span class="math inline">\(\%\)</span> relative error. In contrast to the previous example highlighting the increase in tracking error with increasing source sound distance, these results show a somewhat different trend. The relative error is also much higher, and it may have to do with the positioning of the sound sources in the with reference to the array. The relative location of the sound source affects the tracking accuracy <span class="citation">(Aubauer <a href="#ref-aubauer1996acoustical" role="doc-biblioref">1996</a>)</span>.</p>

</div>
</div>
<div id="future-directions" class="section level2">
<h2><span class="header-section-number">6.5</span> Future directions</h2>
<p><code>tacost</code> as it stands is currently written to implement a first-order assessment of a tracking system’s accuracy. The package has been primarily written keeping acoustic signals propagating through air where the velocity of
sound is assumed to be constant. It may also be used to test tracking in radar or underwater sonar systems, contingent on how uniform the medium of wave propagation is over the distances being studied. As of version 0.1.0
,straight line propagation of signals are simulated, without spherical spreading or atmospheric absorption implemented. Future releases may include such propagation losses. Another important aspect affecting all tracking systems
is the directionality of the sensors (microphones) and emitted signals (animal vocalisations, calibration speakers). A common problem in acoustic tracking with bats and cetaceans is not being able to track animals because their echolocation calls can
be very directional <span class="citation">(Matsuta et al. <a href="#ref-Matsuta2013" role="doc-biblioref">2013</a>; Surlykke <a href="#ref-Surlykke2012" role="doc-biblioref">2012</a>; Koblitz et al. <a href="#ref-Koblitz2016" role="doc-biblioref">2016</a>)</span>. Implementing sensor and source sound directionality will help assessing how many microphones might be required to successfully track animals in their surroundings, and which array geometries are best able to do so.</p>
</div>
<div id="acknowledgements" class="section level2">
<h2><span class="header-section-number">6.6</span> Acknowledgements</h2>
<p>This work was supported by a doctoral fellowship from the German Academic Exchange Service (DAAD) and the International Max Planck Research School for Organismal Biology.
I would like to thank Léna de Framond for generating the acoustic localisation output, Holger R Goerlitz for helpful comments on this manuscript and discussions on the topic of tracking, and the IT team atthe Max-Planck Institute for Ornithology for their support.</p>

</div>
</div>
<h3> References</h3>
<div id="refs" class="references">
<div id="ref-aubauer1996acoustical">
<p>Aubauer, Roland. 1996. “Acoustical Flight Path Tracking of Echolocating Bats.” PhD thesis, Acoustical Society of America.</p>
</div>
<div id="ref-Batstone2019">
<p>Batstone, K, G Floor, T Beleyur, V Larsson, Holger R Goerlitz, M Oskarsson, and K Åström. 2019. “Robust self-calibration of constant offset time-difference-of-arrival.” <em>ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Brighton, United Kingdom, 2019</em> 2019 (2): 4410–4. <a href="https://doi.org/10.1109/ICASSP.2019.8683221.">https://doi.org/10.1109/ICASSP.2019.8683221.</a></p>
</div>
<div id="ref-blumstein2011a">
<p>Blumstein, Daniel T., Daniel J. Mennill, Patrick Clemins, Lewis Girod, Kung Yao, Gail Patricelli, Jill L. Deppe, et al. 2011. “Acoustic Monitoring in Terrestrial Environments Using Microphone Arrays: Applications, Technological Considerations and Prospectus.” <em>Journal of Applied Ecology</em> 48 (3): 758–67. <a href="https://doi.org/10.1111/j.1365-2664.2011.01993.x">https://doi.org/10.1111/j.1365-2664.2011.01993.x</a>.</p>
</div>
<div id="ref-deframond2020">
<p>Framond-Bénard, Léna de, Thejasvi Beleyur, Daniel Lewanzik, and Holger R. Goerlitz. 2020. “Low-Amplitude Echolocation in a Free-Flying Gleaning Bat as a Pre-Adaptation for Aerial-Hunting of Eared Insects.” <em>Manuscript in Preparation</em>.</p>
</div>
<div id="ref-holger_toadsuite_manual">
<p>Goerlitz, Holger R. 2019. “TOADSuite Manual.” Zenodo. <a href="https://doi.org/10.5281/zenodo.3518761">https://doi.org/10.5281/zenodo.3518761</a>.</p>
</div>
<div id="ref-Holderied20032293">
<p>Holderied, M. W., and O. Von Helversen. 2003. “Echolocation Range and Wingbeat Period Match in Aerial-Hawking Bats.” <em>Proceedings of the Royal Society B: Biological Sciences</em> 270 (1530): 2293–9. <a href="https://doi.org/10.1098/rspb.2003.2487">https://doi.org/10.1098/rspb.2003.2487</a>.</p>
</div>
<div id="ref-Hugel2017">
<p>Hügel, Theresa, Vincent van Meir, Amanda Muñoz-Meneses, B. Markus Clarin, Björn M. Siemers, and Holger R. Goerlitz. 2017. “Does similarity in call structure or foraging ecology explain interspecific information transfer in wild Myotis bats?” <em>Behavioral Ecology and Sociobiology</em> 71 (11). <a href="https://doi.org/10.1007/s00265-017-2398-x">https://doi.org/10.1007/s00265-017-2398-x</a>.</p>
</div>
<div id="ref-Koblitz2016">
<p>Koblitz, Jens C., Peter Stilz, Marianne H. Rasmussen, and Kristin L. Laidre. 2016. “Highly directional sonar beam of narwhals (Monodon monoceros) measured with a vertical 16 hydrophone array.” <em>PLoS ONE</em> 11 (11). <a href="https://doi.org/10.1371/journal.pone.0162069">https://doi.org/10.1371/journal.pone.0162069</a>.</p>
</div>
<div id="ref-Lewanzik2018">
<p>Lewanzik, Daniel, and Holger R. Goerlitz. 2018. “Continued source level reduction during attack in the low-amplitude bat Barbastella barbastellus prevents moth evasive flight.” <em>Functional Ecology</em> 32 (5): 1251–61. <a href="https://doi.org/10.1111/1365-2435.13073">https://doi.org/10.1111/1365-2435.13073</a>.</p>
</div>
<div id="ref-Matsuta2013">
<p>Matsuta, Naohiro, Shizuko Hiryu, Emyo Fujioka, Yasufumi Yamada, Hiroshi Riquimaroux, and Yoshiaki Watanabe. 2013. “Adaptive beam-width control of echolocation sounds by cf-fm bats, rhinolophus ferrumequinum nippon, during prey-capture flight.” <em>Journal of Experimental Biology</em> 216 (7): 1210–8. <a href="https://doi.org/10.1242/jeb.081398">https://doi.org/10.1242/jeb.081398</a>.</p>
</div>
<div id="ref-mohl2000sperm">
<p>Møhl, Bertel, Magnus Wahlberg, Peter T Madsen, Lee A Miller, and Annemarie Surlykke. 2000. “Sperm Whale Clicks: Directionality and Source Level Revisited.” <em>The Journal of the Acoustical Society of America</em> 107 (1): 638–48.</p>
</div>
<div id="ref-rhinehart2020a">
<p>Rhinehart, Tessa A., Lauren M. Chronister, Trieste Devlin, and Justin Kitzes. 2020. “Acoustic Localization of Terrestrial Wildlife: Current Practices and Future Opportunities.” <em>Ecology and Evolution</em> n/a (n/a). <a href="https://doi.org/10.1002/ece3.6216">https://doi.org/10.1002/ece3.6216</a>.</p>
</div>
<div id="ref-toadsuite_peterstilz">
<p>Stilz, Peter, Jens Koblitz, and Holger R. Goerlitz. 2019. “TOADSuite Acoustic Tracking Software.”</p>
</div>
<div id="ref-Surlykke2012">
<p>Surlykke, Annemarie. 2012. “Echolocating bats emit a highly directional sonar sound beam in the field.” <em>Proceedings of the Royal Society B: Biological Sciences</em> 276 (1658): 853–60. <a href="https://doi.org/10.1098/rspb.2008.1505">https://doi.org/10.1098/rspb.2008.1505</a>.</p>
</div>
<div id="ref-suzuki2017harkbird">
<p>Suzuki, Reiji, Shiho Matsubayashi, Richard W Hedley, Kazuhiro Nakadai, and Hiroshi G Okuno. 2017. “HARKBird: Exploring Acoustic Interactions in Bird Communities Using a Microphone Array.” <em>Journal of Robotics and Mechatronics</em> 29 (1): 213–23.</p>
</div>
<div id="ref-Taschuk2016">
<p>Taschuk, Morgan, and Greg Wilson. 2016. “Ten Simple Rules for Making Research Software More Robust,” 1–10. <a href="https://doi.org/10.1371/journal.pcbi.1005412">https://doi.org/10.1371/journal.pcbi.1005412</a>.</p>
</div>
<div id="ref-Wahlberg1999">
<p>Wahlberg, Magnus. 1999. “Positioning accuracy of a large‐aperture hydrophone array for sperm whale research.” <em>The Journal of the Acoustical Society of America</em> 105 (2): 1318–8. <a href="https://doi.org/10.1121/1.424536">https://doi.org/10.1121/1.424536</a>.</p>
</div>
<div id="ref-Wilson2012">
<p>Wilson, Greg, D. A. Aruliah, C. Titus Brown, Neil P. Chue Hong, Matt Davis, Richard T. Guy, Steven H. D. Haddock, et al. 2012. “Best Practices for Scientific Computing” 12 (1). <a href="https://doi.org/10.1371/journal.pbio.1001745">https://doi.org/10.1371/journal.pbio.1001745</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="robust-self-calibration-of-constant-offset-time-difference-of-arrival.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="itsfm.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["beleyur_thesis.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
